{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "zp1wzWSisr6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models-pytorch albumentations --quiet\n"
      ],
      "metadata": {
        "id": "U5OK2ERJuAC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from torchvision import transforms as T\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "nPfjZTTNuDaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "LAPwil_GuIva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MriDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = cv2.imread(row['image_filename'], cv2.IMREAD_COLOR)\n",
        "        mask = cv2.imread(row['mask_filename'], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=img, mask=mask)\n",
        "            img, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "        img = T.functional.to_tensor(img)\n",
        "        mask = torch.tensor(mask // 255, dtype=torch.float32).unsqueeze(0)\n",
        "        return img, mask"
      ],
      "metadata": {
        "id": "_TLgpYCfuRul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "])"
      ],
      "metadata": {
        "id": "ybN53_qUuVg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/mri_segmentation/lgg-mri-segmentation/kaggle_3m/data.csv\")\n",
        "valid_df = pd.read_csv(\"valid_data.csv\")\n",
        "\n",
        "train_dataset = MriDataset(train_df, transform=transform)\n",
        "valid_dataset = MriDataset(valid_df, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "Rw9mMXSDudGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = smp.Unet(\n",
        "    encoder_name=\"efficientnet-b7\", encoder_weights=\"imagenet\", in_channels=3, classes=1, activation='sigmoid'\n",
        ").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QHjLRQeujKS",
        "outputId": "7d9e97a0-2c53-49b8-b017-28e8b55032f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n",
            "100%|██████████| 254M/254M [00:13<00:00, 19.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = smp.losses.DiceLoss(mode='binary')\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "lr_scheduler = ReduceLROnPlateau(optimizer, patience=2, factor=0.2)"
      ],
      "metadata": {
        "id": "HZNtt9h4unW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, valid_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for img, mask in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "            img, mask = img.to(device), mask.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(img)\n",
        "            loss = loss_fn(pred, mask)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for img, mask in valid_loader:\n",
        "                img, mask = img.to(device), mask.to(device)\n",
        "                pred = model(img)\n",
        "                val_loss += loss_fn(pred, mask).item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {epoch_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(valid_loader):.4f}\")\n",
        "        lr_scheduler.step(val_loss)\n",
        "\n",
        "    # Save trained model\n",
        "    torch.save(model.state_dict(), \"brain_tumor_segmentation.pth\")\n",
        "    print(\"Model saved.\")\n",
        "\n",
        "# Train model\n",
        "train_model(model, train_loader, valid_loader)"
      ],
      "metadata": {
        "id": "Xw3-rL3UurCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image_path, model_path=\"brain_tumor_segmentation.pth\"):\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    transform = A.Compose([\n",
        "        A.Resize(256, 256),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "    image = transform(image=image)['image']\n",
        "    image = T.functional.to_tensor(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(image).squeeze().cpu().numpy()\n",
        "    return pred\n"
      ],
      "metadata": {
        "id": "varanCoOu6w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TL9rzV8PuwAL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}